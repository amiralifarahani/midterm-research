# WebProgramming-final-research

<div dir='rtl'>
<h1>کافکا</h1>

<h2>
تاریخچه
</h2>

<p>
آپاچی کافکا در ابتدا توسط لینکدین  توسعه یافت و در اوایل سال 2011 بصورت نرم افزار متن باز در آمد. در نوامبر ۲۰۱۴ ، چندین مهندس که در لینکدین  بر روی کافکا کار می‌کردند یک شرکت جدید به نام Confluent  ایجاد کرده و به صورت انحصاری بر روی توسعه کافکا کار کردند. بر اساس یک پست در سال 2014 به نظر می رسد که جی کربس نام این برنامه را از نام فرانتس کافکا نویسنده آلمانی برداشت کرده است.
</p>
</br>
</br>

<h2>
آپاچی کافکا چیست؟
</h2>

<p>
آپاچی کافکا یک پلتفرم توزیع‌شده برای پردازش داده های جریانی بوده و قادر به رسیدگی و پردازش چندین تریلیون رویداد است به صورت همزمان است. کافکا در ابتدا به عنوان یک ابزار برای ارسال پیامهایی با تعداد بالا بکار برده می شد. کافکا از زمان ایجاد و منبع باز شدن توسط لینکدین در سال ۲۰۱۱ ، به سرعت از ارسال پیام به یک پلتفرم پردازش توزیعی کامل تبدیل شده است.

آپاچی کافکا، به عنوان یک پلتفرم داده های در جریان، دارای قابلیتهایی ازقبیل زمان پاسخ کوتاه، کارایی بالاو تحمل خطا بوده و قادر به پردازش جریانهایی سریع از رویدادها می باشد. کافکا، برای پشتیبانی از برنامه های کاربردی مشتری و اتصال سیستم های پایین دست با داده های زمان واقعی پاسخ های در حد میلی ثانیه فراهم می کند.

</p>
</br>
</br>

<h2>
کاربرد های کافکا
</h2>

<p>
<ul>
<li>
ایجاد خطوط انتقال داده های جریانی و به هنگام که داده ها را میان سیستمها و برنامه ها بصورت قابل اطمینانی انتقال داده و رد و بدل می کند.
</li>
<li> ایجاد برنامه های کاربردی برای داده های جریانی و به هنگام که به موقع نسبت به جریانی از داده ها واکنش نشان داده و آنها را انتقال می دهد.</li>
</ul>
</p>
</br>
</br>

<h2>
ساختار و نحوه کار کافکا
</h2>

<p>
قبل از اینکه به ساختار کافکا بپردازیم ابتدا چند اصطلاح را توضیح می دهیم:

 <li>
 کافکا به صورت خوشه ای بر روی یک یا چند سرور کار می کند
 </li>

  <li>
 کافکا جریان داده ها و رکورد ها را در ساختارهایی به نام تاپیک( topics) ذخیره می کند
 </li>

  <li>
  هر رکوردی دارای یک کلید، یک مقدار و یک برچسب زمانی می باشد تا بصورت مجزا از سایر رکورد ها مشخص باشد
 </li>

</br>
 کافکا دارای 4 رابط کاربری برای برنامه خود می باشد که هر کدام نقشی در مجموعه فعالیتهای کافکا دارند. این رابطها شامل:

  <li>
  رابط تولید کننده (Producer) که به یک برنامه اجازه می دهد رشته هایی از رکورد ها را بر روی یک یا چند تاپیک کافکا منتشر کند
 </li>

  <li>
   رابط مصرف کننده(Consumer) که به یک برنامه اجازه می دهد به یک یا چند تاپیک متصل شده و رکورهای موجود را پردازش کند
 </li>
  <li>
  رابط جریانی (Streams) که به یک برنامه اجازه می دهد بصورت پردازشگر داده های جریانی عمل کرده و داده های ورودی موجود بر یک یا چند تاپیک را مصرف کرده و خروجی آن نیز تولید جریانی از داده ها بر روی تاپیکهای خروجی بوده و بصورت موثری جریانهای ورودی را به خروجی تبدیل می کند.
 </li>

  <li>
   رابط اتصال دهنده(Connector) که اجازه ساخت و اجرای تولید کننده ها و مصرف کننده هایی با قابلیت استفاده مجدد را می دهد که تاپیکهای کافکا را به برنامه ها و سیستمهای داده ای موجود متصل می کند. مثلا یک اتصال دهنده به یک پایگاه داده رابطه ای می تواند هر نوع تغییری که بر روی یک جدول اعمال شده را ثبت و ضبط کند.  
 </li>
شکل زیر رابط های کاربری و نحوه کار کافکا را بصورت شماتیک نشان می دهد.

<img src='./neda/one.JPG'>

</br>
بطور کلی نحوه کار کافکا بصورت ذیل است:

کافکا پیامهایی را که از بسیاری از "تولید کنندگان" دریافت می کند را ذخیره کرده و داده ها بدین صورت بر روی پارتیشن های گوناگونی در "تاپیکهای" مختلف توزیع شده و پارتیشن بندی می شوند. در هر پارتیشن پیامها با هم شاخص گذاری شده و با یک برچسب زمانی ذخیره می شوند. سایر فرایندها مثل "مصرف کنندگان" می توانند پیامها را از پارتیشنها دریافت کرده و اطلاعات مورد نظر خود را درخواست کنند. کافکا بر روی خوشه هایی از یک یا چند سرور اجرا می شود و پارتیشنها می توانند بر روی چندین نود مختلف توزیع شوند.

آپاچی کافکا هنگامی که همراه با آپاچی استورم، اچ بیس و اسپارک استفاده شود به طور موثری می تواند داده‌های بلادرنگ و جریان را پردازش کند. اگر کافکا به عنوان یک خوشه روی چندین سرور پیکر بندی و اجرا شود در اینصورت به کمک 4 رابط کاربری خود براحتی عملیات انتشار و دریافت و پردازش اطلاعات را به سرعت و با کارایی بالا انجام می دهد.

توانایی کافکا برای ارایه جریان‌های عظیم داده و پیام ،همراه با تحمل خطای بالا ، آن را جایگزین برخی از سیستم‌های پیام‌رسانی مرسوم مانند JMS ، AMQPو غیره کرده است.

</p>
</br>
</br>

<h2>
جریان رویداد چیست؟
</h2>

<p>
جریان رویداد معادل دیجیتالی سیستم عصبی مرکزی بدن انسان است. این پایه تکنولوژیکی برای دنیای «همیشه فعال» است که در آن کسب‌وکارها به طور فزاینده‌ای توسط نرم‌افزار تعریف و خودکار می‌شوند، و در آن کاربر نرم‌افزار بیشتر نرم‌افزار است.

از نظر فنی، جریان رویداد عملی است که داده‌ها را در زمان واقعی از منابع رویداد مانند پایگاه‌های داده، حسگرها، دستگاه‌های تلفن همراه، سرویس‌های ابری و برنامه‌های نرم‌افزاری در قالب جریان رویدادها ضبط می‌کند. ذخیره سازی این جریان های رویداد به صورت بادوام برای بازیابی بعدی. دستکاری، پردازش، و واکنش به جریان رویداد در زمان واقعی و همچنین به صورت گذشته نگر. و مسیریابی جریان رویداد به فن آوری های مختلف مقصد در صورت لزوم. بنابراین جریان رویداد جریان و تفسیر مداوم داده ها را تضمین می کند تا اطلاعات مناسب در مکان مناسب و در زمان مناسب باشد.

</p>
</br>
</br>

<h2>
برای چه چیزی می توانم از جریان رویداد استفاده کنم؟
</h2>

<p>
جریان رویداد برای طیف گسترده ای از موارد استفاده در بسیاری از صنایع و سازمان ها اعمال می شود. نمونه های فراوان آن عبارتند از:

برای پردازش پرداخت ها و تراکنش های مالی در زمان واقعی، مانند بورس ها، بانک ها و بیمه ها.

برای ردیابی و نظارت بر خودروها، کامیون ها، ناوگان و محموله ها در زمان واقعی، مانند لجستیک و صنعت خودرو.

برای گرفتن و تجزیه و تحلیل مداوم داده های حسگر از دستگاه های IoT یا سایر تجهیزات، مانند کارخانه ها و پارک های بادی.

برای جمع آوری و واکنش فوری به تعاملات و سفارشات مشتری، مانند خرده فروشی، صنعت هتل و مسافرت، و برنامه های کاربردی تلفن همراه.
برای نظارت بر بیماران در مراقبت های بیمارستانی و پیش بینی تغییرات در شرایط برای اطمینان از درمان به موقع در مواقع اضطراری.

برای اتصال، ذخیره و در دسترس قرار دادن داده های تولید شده توسط بخش های مختلف یک شرکت.

به عنوان پایه ای برای پلتفرم های داده، معماری های رویداد محور و میکروسرویس ها خدمت کند.

</p>
</br>
</br>

<h2>
Kafka APIs
</h2>

<p dir='rtl'>
علاوه بر ابزار خط فرمان برای وظایف مدیریت و مدیریت، کافکا دارای پنج API اصلی برای جاوا و اسکالا است:

ادمین ای پی آی برای مدیریت و بازرسی موضوعات، کارگزاران و سایر اشیاء کافکا.
API تولیدکننده برای انتشار (نوشتن) جریانی از رویدادها در یک یا چند موضوع کافکا.
Consumer API برای اشتراک (خواندن) یک یا چند موضوع و پردازش جریان رویدادهای تولید شده برای آنها.
Kafka Streams API برای پیاده‌سازی برنامه‌های پردازش جریانی و میکروسرویس‌ها. این توابع سطح بالاتری را برای پردازش جریان های رویداد ارائه می دهد، از جمله تبدیل ها، عملیات حالت دار مانند تجمیع ها و پیوستن ها، پنجره سازی، پردازش بر اساس زمان رویداد و موارد دیگر. ورودی از یک یا چند موضوع خوانده می شود تا خروجی به یک یا چند موضوع تولید شود و به طور موثر جریان های ورودی را به جریان های خروجی تبدیل کند.
Kafka Connect API برای ساخت و اجرای اتصالات واردات/صادرات داده های قابل استفاده مجدد که جریان هایی از رویدادها را از و به سیستم ها و برنامه های خارجی مصرف (خواندن) یا تولید (نوشتن) می کنند تا بتوانند با کافکا یکپارچه شوند. به عنوان مثال، یک اتصال دهنده به یک پایگاه داده رابطه ای مانند PostgreSQL ممکن است هر تغییری را در مجموعه ای از جداول ثبت کند. با این حال، در عمل، شما معمولاً نیازی به پیاده سازی کانکتورهای خود ندارید، زیرا جامعه کافکا در حال حاضر صدها کانکتور آماده برای استفاده را ارائه می دهد.

</p>
</br>
</br>

<h2>Messaging</h2>
<p>
کافکا به عنوان جایگزینی برای یک واسطه پیام سنتی تر به خوبی عمل می کند. واسطه‌های پیام به دلایل مختلفی (برای جدا کردن پردازش از تولیدکنندگان داده، بافر کردن پیام‌های پردازش نشده و غیره) استفاده می‌شوند. در مقایسه با اکثر سیستم های پیام رسانی، کافکا دارای توان عملیاتی، پارتیشن بندی داخلی، تکرار و تحمل خطای بهتری است که آن را به یک راه حل خوب برای کاربردهای پردازش پیام در مقیاس بزرگ تبدیل می کند.
در تجربه ما، استفاده از پیام‌رسانی اغلب نسبتاً کم توان است، اما ممکن است به تأخیر انتها به انتها کم نیاز داشته باشد و اغلب به تضمین‌های دوام قوی که کافکا ارائه می‌کند بستگی دارد.

در این حوزه کافکا با سیستم های پیام رسانی سنتی مانند ActiveMQ یا RabbitMQ قابل مقایسه است.

</p>
</br>
</br>

<h2>معیارها</h2>
<p>
کافکا اغلب برای داده های نظارت عملیاتی استفاده می شود. این شامل جمع آوری آمار از برنامه های کاربردی توزیع شده برای تولید فیدهای متمرکز داده های عملیاتی است.
تجمیع ورود به سیستم
بسیاری از مردم از کافکا به عنوان جایگزینی برای راه حل تجمع سیاهه ها استفاده می کنند. تجمیع گزارش‌ها معمولاً فایل‌های گزارش فیزیکی را از سرورها جمع‌آوری می‌کند و آنها را برای پردازش در یک مکان مرکزی (یک سرور فایل یا HDFS) قرار می‌دهد. کافکا جزئیات فایل‌ها را خلاصه می‌کند و انتزاعی تمیزتر از داده‌های گزارش یا رویداد را به عنوان جریانی از پیام‌ها ارائه می‌کند. این امکان پردازش با تأخیر کمتر و پشتیبانی آسان تر از منابع داده های متعدد و مصرف داده های توزیع شده را فراهم می کند. در مقایسه با سیستم‌های log-centric مانند Scribe یا Flume، کافکا عملکرد به همان اندازه خوب، تضمین‌های دوام قوی‌تر به دلیل تکرار، و تأخیر انتها به انتها بسیار کمتر را ارائه می‌دهد.
</p>
</br>
</br>

<h2>پردازش جریان</h2>
<p>
بسیاری از کاربران کافکا داده‌ها را در خطوط لوله پردازش متشکل از چند مرحله پردازش می‌کنند، که در آن داده‌های ورودی خام از موضوعات کافکا مصرف می‌شود و سپس تجمیع، غنی‌سازی می‌شود یا به‌طور دیگری به موضوعات جدید برای مصرف بیشتر یا پردازش بعدی تبدیل می‌شود. برای مثال، یک خط لوله پردازش برای توصیه مقالات خبری ممکن است محتوای مقاله را از فیدهای RSS بخزد و آن را در یک موضوع "مقالات" منتشر کند. پردازش بیشتر ممکن است این محتوا را عادی یا تکراری کند و محتوای مقاله پاک شده را در یک موضوع جدید منتشر کند. در مرحله نهایی پردازش ممکن است سعی شود این محتوا به کاربران توصیه شود. چنین خطوط لوله پردازشی نمودارهایی از جریان داده های بلادرنگ را بر اساس موضوعات فردی ایجاد می کند. با شروع نسخه 0.10.0.0، یک کتابخانه پردازش جریانی سبک اما قدرتمند به نام Kafka Streams در آپاچی کافکا برای انجام چنین پردازش داده‌ای همانطور که در بالا توضیح داده شد در دسترس است. به غیر از Kafka Streams، ابزارهای جایگزین متن باز پردازش جریان شامل Apache Storm و Apache Samza هستند.
</p>
</br>
</br>

<h2>
خب حالا بریم سراف شروع کار با کافکا
</h2>

<p>
مرحله 1: کافکا را دریافت کنید
آخرین نسخه کافکا را دانلود کنید و آن را استخراج کنید:

میتوانید از لینک زیر هم دانلود کنید

[DOWNLOAD](https://www.apache.org/dyn/closer.cgi?path=/kafka/3.4.0/kafka_2.13-3.4.0.tgz)

</p>

<section dir="ltr">

```
$ tar -xzf kafka_2.13-3.4.0.tgz
$ cd kafka_2.13-3.4.0
```

</section>

<p>
مرحله 2: محیط کافکا را شروع کنید
توجه: محیط محلی شما باید Java 8+ را نصب کرده باشد.

آپاچی کافکا را می توان با استفاده از ZooKeeper یا KRaft راه اندازی کرد. برای شروع با هر یک از پیکربندی ها یکی از بخش های زیر را دنبال کنید اما نه هر دو را.

</p>

<h2>
کافکا با ZooKeeper
</h2>

<p>
دستورات زیر را اجرا کنید تا همه سرویس ها به ترتیب درست شروع شوند:
</p>

<section dir="ltr">

```
# Start the ZooKeeper service
$ bin/zookeeper-server-start.sh config/zookeeper.properties
```

</section>

<p>ترمینال دیگری را باز کنید و کد زیر را اجرا کنید</p>

<section dir="ltr">

```
# Start the Kafka broker service
$ bin/kafka-server-start.sh config/server.properties
```

</section>

<p>
هنگامی که همه سرویس ها با موفقیت راه اندازی شدند، یک محیط اولیه کافکا در حال اجرا و آماده برای استفاده خواهید داشت.
</p>

</br>
</br>

<h2 dir='ltr'>
Kafka with KRaft
</h2>

<p>
یک Cluster UUIDایجاد کنید و کد زیر را اجرا کنید

<section dir="ltr">

```
$ KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"
```

</section>

سپس فهرست راهنماها را قالب بندی کنید

<section dir="ltr">

```
$ bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties
```

</section>

سرور کافکا را راه اندازی کنید

<section dir="ltr">

```
$ bin/kafka-server-start.sh config/kraft/server.properties
```

</section>

هنگامی که سرور کافکا با موفقیت راه اندازی شد، یک محیط اولیه کافکا در حال اجرا و آماده برای استفاده خواهید داشت.

مرحله 3: یک موضوع برای ذخیره رویدادهای خود ایجاد کنید
کافکا یک پلتفرم پخش رویداد توزیع شده است که به شما امکان می‌دهد رویدادها را بخوانید، بنویسید، ذخیره کنید و پردازش کنید (که رکوردها یا پیام‌ها در اسناد نیز نامیده می‌شوند) در بسیاری از ماشین‌ها.

رویدادهای مثال عبارتند از تراکنش‌های پرداخت، به‌روزرسانی‌های موقعیت جغرافیایی از تلفن‌های همراه، سفارش‌های حمل و نقل، اندازه‌گیری حسگر از دستگاه‌های IoT یا تجهیزات پزشکی و موارد دیگر. این رویدادها در موضوعات سازماندهی و ذخیره می شوند. بسیار ساده شده، یک موضوع شبیه به یک پوشه در یک سیستم فایل است و رویدادها فایل‌های موجود در آن پوشه هستند.

حال باید در ترمینال دیگری کد زیر را اجرا نمایید.

<section dir="ltr">

```
$ bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092
```

</section>

همه ابزارهای خط فرمان کافکا دارای گزینه های اضافی هستند: دستور kafka-topics.sh را بدون هیچ آرگومانی برای نمایش اطلاعات استفاده اجرا کنید.

<section dir="ltr">

```
$ bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092
Topic: quickstart-events        TopicId: NPmZHyhbR9y00wMglMH2sg PartitionCount: 1       ReplicationFactor: 1	Configs:
    Topic: quickstart-events Partition: 0    Leader: 0   Replicas: 0 Isr: 0

```

</section>

مرحله 4: برخی از رویدادها را در موضوع بنویسید
مشتری کافکا برای نوشتن (یا خواندن) رویدادها از طریق شبکه با کارگزاران کافکا ارتباط برقرار می کند. پس از دریافت، کارگزاران رویدادها را تا زمانی که شما نیاز دارید - حتی برای همیشه - به روشی بادوام و بدون عیب ذخیره می کنند.

برای نوشتن چند رویداد در موضوع خود، کلاینت سازنده کنسول را اجرا کنید. به‌طور پیش‌فرض، هر خطی که وارد می‌کنید منجر به نوشتن یک رویداد جداگانه برای موضوع می‌شود.

<section dir="ltr">

```
$ bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092
This is my first event
This is my second event
```

</section>

مرحله 5: رویدادها را بخوانید

<section dir="ltr">

```
$ bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092
This is my first event
This is my second event
```

</section>

به راحتی آزمایش کنید: به عنوان مثال، برای نوشتن رویدادهای اضافی به پایانه تولیدکننده خود (مرحله قبلی) برگردید و ببینید که چگونه رویدادها بلافاصله در پایانه مصرف کننده شما نشان داده می شوند.

از آنجایی که رویدادها به طور پایدار در کافکا ذخیره می شوند، می توانند به تعداد دفعات و هر تعداد مصرف کننده که بخواهید خوانده شوند. با باز کردن یک جلسه ترمینال دیگر و اجرای مجدد دستور قبلی، به راحتی می توانید این موضوع را تأیید کنید.

مرحله 6: داده های خود را به عنوان جریان رویدادها با اتصال کافکا وارد یا صادر کنید
احتمالاً در سیستم‌های موجود مانند پایگاه‌های داده رابطه‌ای یا سیستم‌های پیام‌رسان سنتی، همراه با بسیاری از برنامه‌هایی که قبلاً از این سیستم‌ها استفاده می‌کنند، داده‌های زیادی دارید. Kafka Connect به شما اجازه می دهد تا به طور مداوم داده های سیستم های خارجی را به کافکا وارد کنید و بالعکس. این یک ابزار توسعه پذیر است که کانکتورهایی را اجرا می کند که منطق سفارشی را برای تعامل با یک سیستم خارجی پیاده سازی می کند. بنابراین، ادغام سیستم های موجود با کافکا بسیار آسان است. برای آسان‌تر کردن این فرآیند، صدها کانکتور از این قبیل به راحتی در دسترس هستند.

در این شروع سریع، نحوه اجرای Kafka Connect را با کانکتورهای ساده ای خواهیم دید که داده ها را از یک فایل به یک موضوع کافکا وارد می کند و داده ها را از یک موضوع کافکا به یک فایل صادر می کند.

ابتدا مطمئن شوید که connect-file-3.4.0.jar را به ویژگی plugin.path در پیکربندی Connect worker اضافه کنید. برای این شروع سریع، از یک مسیر نسبی استفاده می کنیم و بسته کانکتورها را به عنوان یک uber jar در نظر می گیریم، که زمانی کار می کند که دستورات شروع سریع از دایرکتوری نصب اجرا شوند. با این حال، شایان ذکر است که برای استقرار تولید، استفاده از مسیرهای مطلق همیشه ارجحیت دارد. برای توضیح دقیق نحوه تنظیم این پیکربندی به plugin.path مراجعه کنید.

فایل config/connect-standalone.properties را ویرایش کنید، ویژگی پیکربندی plugin.path را با موارد زیر اضافه یا تغییر دهید و فایل را ذخیره کنید:

<section dir="ltr">

```
> echo "plugin.path=libs/connect-file-3.4.0.jar"
```

</section>

سپس، با ایجاد برخی از داده های اولیه برای آزمایش شروع کنید:

<section dir="ltr">

```
> echo -e "foo\nbar" > test.txt
```

</section>

یا در ویندوز:

<section dir="ltr">

```
> echo foo> test.txt
> echo bar>> test.txt
```

</section>

در مرحله بعد، دو کانکتور را در حالت مستقل اجرا می کنیم، به این معنی که آنها در یک فرآیند واحد، محلی و اختصاصی اجرا می شوند. ما سه فایل پیکربندی را به عنوان پارامتر ارائه می کنیم. اولین مورد همیشه پیکربندی فرآیند اتصال کافکا است که شامل پیکربندی رایج مانند کارگزاران کافکا برای اتصال به و قالب سریال سازی برای داده ها است. فایل های پیکربندی باقیمانده هر کدام یک کانکتور برای ایجاد مشخص می کنند. این فایل ها شامل یک نام کانکتور منحصر به فرد، کلاس اتصال دهنده برای نمونه سازی و هر پیکربندی دیگر مورد نیاز کانکتور هستند.

<section dir="ltr">

```
> bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties
```

</section>

این فایل‌های پیکربندی نمونه، همراه با کافکا، از پیکربندی کلاستر محلی پیش‌فرض که قبلاً شروع کرده‌اید استفاده می‌کنند و دو رابط ایجاد می‌کنند: اولی یک رابط منبع است که خطوط را از یک فایل ورودی می‌خواند و هر کدام را به یک موضوع کافکا تولید می‌کند و دومی یک رابط سینک است. که پیام های یک موضوع کافکا را می خواند و هر کدام را به صورت یک خط در یک فایل خروجی تولید می کند.

در طول راه‌اندازی، تعدادی پیام گزارش مشاهده خواهید کرد، از جمله برخی از آنها که نشان می‌دهند اتصال‌دهنده‌ها در حال نمونه‌سازی هستند. هنگامی که فرآیند اتصال کافکا شروع شد، کانکتور منبع باید شروع به خواندن خطوط از test.txt و تولید آنها به تست اتصال مبحث کند، و رابط سینک باید شروع به خواندن پیام‌ها از تست اتصال موضوع کند و آنها را در آزمون فایل بنویسد. .sink.txt. با بررسی محتویات فایل خروجی می‌توانیم تأیید کنیم که داده‌ها از طریق کل خط لوله تحویل داده شده است:

<section dir="ltr">

```
> more test.sink.txt
foo
bar
```

</section>

توجه داشته باشید که داده‌ها در تست اتصال موضوع کافکا ذخیره می‌شوند، بنابراین می‌توانیم یک مصرف‌کننده کنسول را برای دیدن داده‌های موضوع اجرا کنیم (یا از کد مصرف‌کننده سفارشی برای پردازش آن استفاده کنیم):

<section dir="ltr">

```
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning
{"schema":{"type":"string","optional":false},"payload":"foo"}
{"schema":{"type":"string","optional":false},"payload":"bar"}
...
```

</section>

اتصال دهنده ها به پردازش داده ها ادامه می دهند، بنابراین ما می توانیم داده ها را به فایل اضافه کنیم و شاهد حرکت آن در خط لوله باشیم:

<section dir="ltr">

```
> echo Another line>> test.txt

```

</section>

باید این خط را در خروجی مصرف کننده کنسول و در فایل سینک مشاهده کنید.

مرحله 7: رویدادهای خود را با کافکا استریمز پردازش کنید
هنگامی که داده های شما به عنوان رویداد در کافکا ذخیره می شوند، می توانید داده ها را با کتابخانه مشتری Kafka Streams برای جاوا/اسکالا پردازش کنید. این به شما امکان می‌دهد تا برنامه‌ها و ریزسرویس‌های لحظه‌ای حیاتی را پیاده‌سازی کنید، جایی که داده‌های ورودی و/یا خروجی در موضوعات کافکا ذخیره می‌شوند. Kafka Streams سادگی نوشتن و استقرار برنامه‌های جاوا و اسکالا استاندارد در سمت کلاینت را با مزایای فناوری خوشه سمت سرور کافکا ترکیب می‌کند تا این برنامه‌ها را بسیار مقیاس‌پذیر، الاستیک، مقاوم در برابر خطا و توزیع کند. این کتابخانه دقیقاً یک بار پردازش، عملیات و تجمیع حالت، پنجره‌سازی، پیوستن، پردازش بر اساس زمان رویداد و موارد دیگر را پشتیبانی می‌کند.

برای اولین بار، نحوه پیاده سازی الگوریتم محبوب WordCount را در اینجا آورده ایم:

<section dir="ltr">

```
KStream<String, String> textLines = builder.stream("quickstart-events");

KTable<String, Long> wordCounts = textLines
            .flatMapValues(line -> Arrays.asList(line.toLowerCase().split(" ")))
            .groupBy((keyIgnored, word) -> word)
            .count();

wordCounts.toStream().to("output-topic", Produced.with(Serdes.String(), Serdes.Long()));
```

</section>

مرحله 8: محیط کافکا را خاتمه دهید
اکنون که به پایان شروع سریع رسیده‌اید، با خیال راحت محیط کافکا را خراب کنید—یا به بازی کردن ادامه دهید.

اگر قبلاً این کار را نکرده‌اید، با Ctrl-C مشتریان تولیدکننده و مصرف‌کننده را متوقف کنید.
کارگزار کافکا را با Ctrl-C متوقف کنید.
در نهایت، اگر بخش Kafka with ZooKeeper دنبال شد، سرور ZooKeeper را با Ctrl-C متوقف کنید.
اگر همچنین می‌خواهید داده‌های محیط کافکا محلی خود را حذف کنید، از جمله رویدادهایی که در طول مسیر ایجاد کرده‌اید، دستور را اجرا کنید:

<section dir="ltr">

```
$ rm -rf /tmp/kafka-logs /tmp/zookeeper /tmp/kraft-combined-logs

```

</section>

پس از طی این مراحل
شما شروع سریع آپاچی کافکا را با موفقیت به پایان رساندید.

برای کسب اطلاعات بیشتر مراحل زیر را پیشنهاد می کنیم:

مقدمه کوتاه را بخوانید تا با نحوه عملکرد کافکا در سطح بالا، مفاهیم اصلی آن و مقایسه آن با سایر فناوری‌ها آشنا شوید. برای درک بیشتر کافکا، به مستندات مراجعه کنید.
موارد استفاده را مرور کنید تا بدانید چگونه سایر کاربران در جامعه جهانی ما از کافکا ارزش می‌گیرند.
به یک گروه ملاقات محلی کافکا بپیوندید و گفتگوهای نشست کافکا، کنفرانس اصلی جامعه کافکا را تماشا کنید.

</p>

</br>
</br>

<h2 dir='ltr'>
Producer API
</h2>

<p>
	
<secion dir='rtl' >
	

Producer API به برنامه‌ها اجازه می‌دهد تا جریان‌هایی از داده‌ها را به موضوعاتی در خوشه کافکا ارسال کنند.
نمونه هایی که نحوه استفاده از سازنده را نشان می دهد در جاوادوک آورده شده است.

برای استفاده از تولید کننده، می توانید از وابستگی maven زیر استفاده کنید:
		
</section>
		
<secion dir='ltr' >
```
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-clients</artifactId>
	<version>3.4.0</version>
</dependency>
```
		
</section>

</p>
</br>
</br>

<h2 dir='ltr'>
Consumer API
</h2>

<p dir="rtl" >
Consumer API به برنامه‌ها اجازه می‌دهد تا جریان‌های داده‌ها را از موضوعات در خوشه کافکا بخوانند.
مثال هایی که نحوه استفاده از مصرف کننده را نشان می دهد در جاوادوک آورده شده است.

برای استفاده از مصرف کننده، می توانید از وابستگی maven زیر استفاده کنید:

<section dir="ltr">

```
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-clients</artifactId>
	<version>3.4.0</version>
</dependency>
```

</section>

</p>
</br>
</br>

<h2 dir='ltr'>
Streams API
</h2>

<p dir="rtl">
Streams API اجازه می دهد تا جریان های داده را از موضوعات ورودی به موضوعات خروجی تبدیل کند.
نمونه هایی که نحوه استفاده از این کتابخانه را نشان می دهد در جاوادوک آورده شده است

اسناد اضافی در مورد استفاده از Streams API در اینجا موجود است.

برای استفاده از Kafka Streams می توانید از وابستگی maven زیر استفاده کنید:

<section dir="ltr">

```
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-streams</artifactId>
	<version>3.4.0</version>
</dependency>
```

</section>

<div dir="rtl">
هنگام استفاده از Scala، می‌توانید به صورت اختیاری کتابخانه kafka-streams-scala را اضافه کنید. اسناد اضافی در مورد استفاده از Kafka Streams DSL برای Scala در راهنمای توسعه دهنده موجود است.

برای استفاده از Kafka Streams DSL for Scala for Scala 2.13 می توانید از وابستگی maven زیر استفاده کنید:

</div>

<section dir="ltr">

```
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-streams-scala_2.13</artifactId>
	<version>3.4.0</version>
</dependency>
```

</section>

</p>
</br>
</br>

<h2 dir="ltr">
Connect API
</h2>

<p dir="rtl">
Connect API اجازه می دهد تا اتصال دهنده هایی را پیاده سازی کند که به طور مداوم از برخی از سیستم های داده منبع به کافکا کشیده می شوند یا از کافکا به برخی از سیستم های داده سینک فشار می آورند.
بسیاری از کاربران Connect نیازی به استفاده مستقیم از این API نخواهند داشت، اگرچه می‌توانند بدون نیاز به نوشتن کد از کانکتورهای از پیش ساخته شده استفاده کنند. اطلاعات اضافی در مورد استفاده از Connect در اینجا موجود است.

کسانی که می خواهند کانکتورهای سفارشی را پیاده سازی کنند می توانند javadoc را ببینند.

</p>
</br>
</br>

<h2 dir="ltr">
Admin API
</h2>

<p>
Admin API از مدیریت و بازرسی موضوعات، بروکرها، acls و سایر اشیاء کافکا پشتیبانی می کند.
برای استفاده از Admin API، وابستگی Maven زیر را اضافه کنید:

<section dir="ltr">

```
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-clients</artifactId>
	<version>3.4.0</version>
</dependency>
```

</section>

</p>
</br>
</br>

## طراحی

کافکا باید بتواند تمامی داده‌های real-time یک شرکت بزرگ را مدیریت کند. همچنین باید بتواند جریان وقایع را با حجم بالایی پشتیبانی کند و feedها را به صورت توزیع شده پردازش کند.

برای برآورده کردن این مقاصد طراحی کافکا دارای چند معیار کلیدی است که آنها را در چند بخش معرفی می‌کنیم.

### the producer

#### تنظیم لود

producer داده را بدون مداخله با brokerای که مسئول partition است ارسال می‌کند. به همین خاطر هر گره کافکا می‌تواند به درخواست‌های در رابطه با زنده بودن هر سرور و محل مسئول partitionها در هر زمان پاسخ بدهد تا producer درخواست خود را به درستی مسیردهی کند.

برای

## عملیات

### حذف و اضافه کردن topic

می‌توان topicها را به صورت دستی ایجاد کرد یا هنگامی که برای اولین بار داده‌ای را در یک topic ناموجود منتشر می‌کنیم خودکار ایجاد می‌شوند.

اضافه کردن و تغییر topicها به شکل زیر است:

```script
  > bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name --partitions 20 --replication-factor 3 --config x=y
```

معیار replication factor کنترل می‌کند که چند سرور هر پیغام را تکثیر می‌کند. اگر replication factor برابر با 3 باشد، با fail شدن 2 سرور دسترسی به داده از بین می‌رود. توصیه می‌شود این مقدار 2 یا 3 باشد.

تعداد partitions کنترل می‌کند که topic به چند log تقسیم می‌شود. تعداد partitionها از جهات مختلفی تاثیر گذار است. اولا هر partition باید بر روی یک سرور جا بشود. دوما تعداد partitionها بر حداکثر میزان موازی‌سازی مشتریان موثر است. هر partition در فولدری مخصوص به خود در log directory کافکا ذخیره می‌شود. نام این فولدرها شامل نام topic، یک خط تیره (-) و آی دی partition خواهد بد.

این تنظیمات نوشته شده در command line تنظیمات پیش فرض سرور را تغییر خواند داد.

### تغییر topicها

می‌توان با استفاده از همان دستورات مشابه می‌توانت تنظیمات یک topic را تغییر داد.

برای اضافه کردن partition دستور زیر را داریم:

```terminal
  > bin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic my_topic_name --partitions 40
```

در حال حاضر کافکا از دستور کاهش partition پشتیبانی نمی‌کند.

اضافه کردن تنظیمات:

```terminal
  > bin/kafka-configs.sh --bootstrap-server broker_host:port --entity-type topics --entity-name my_topic_name --alter --add-config x=y
```

حذف کردن تنظیمات:

```terminal
  > bin/kafka-configs.sh --bootstrap-server broker_host:port --entity-type topics --entity-name my_topic_name --alter --delete-config x
```

و حذف کردن topic:

```terminal
  > bin/kafka-topics.sh --bootstrap-server broker_host:port --delete --topic my_topic_name
```

### shutdown ظریف

کلاستر کافکا به طور خودکار هر خاموشی یا failure را در brokerها تشخیص می‌دهد و رهبر جدید را برای partitionهای آن ماشین انتخاب می‌کند، چه خاموشی سرور بر اثر failure باشد و چه به صورت عمدی از دور خارج شود.

برای خارج کردن عمدی یک سرور از دور، کافکا روشی ظریف‌تر از صرفا کشتن سرور ارائه می‌دهد. این روش دو بهینه سازی دارد.

1. تمام لاگ‌های سرور با دیسک همگام سازی می‌شوند تا هنگام restart نیازی به بازیابی لاگ‌ها نباشد. به همین دلیل سرعت restart افزایش می‌یابد.

1. قبل از خاموشی تمامی partitionهایی که سرور رهبر آنها بوده به دیگر سرورهایی که آنها را تکثیر می‌کردند منتقل می‌شوند. بدین صورت فرایند انتقال رهبری تسریع می‌شود و زمان در دسترس نبودن partition به حداقل می‌رسد.

همگام‌سازی لاگ‌ها در هر حالت از توقف سرور جز با hard kill انجام می‌شود. اما انتقلب کنترل شده رهبری به یک تنظیمات خاص نیاز دارد:

```terminal
controlled.shutdown.enable=true
```

### چک کردن جایگاه مصرف‌کنندگان

در کافکا ابزاری وجود دارد که موقعیت همه مصرف‌کنندگان را در یک گروه مصرف‌کننده نشان می‌دهد و همچنین نشان می‌دهد که چقدر از انتهای لاگ عقب هستند. اجرای این ابزار در یک گروه مصرف کننده به نام my-group که موضوعی به نام my-topic را مصرف می کند به صورت زیر است:

```terminal
  > bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group
```

که خروجی آن به صورت زیر خواهد بود:

```terminal
  TOPIC                          PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG        CONSUMER-ID                                       HOST                           CLIENT-ID
  my-topic                       0          2               4               2          consumer-1-029af89c-873c-4751-a720-cefd41a669d6   /127.0.0.1                     consumer-1
  my-topic                       1          2               3               1          consumer-1-029af89c-873c-4751-a720-cefd41a669d6   /127.0.0.1                     consumer-1
  my-topic                       2          2               3               1          consumer-2-42c1abd4-e3b2-425d-a8bb-e1ea49b29bb2   /127.0.0.1                     consumer-2
```

### مدیریت گروه‌های مصرف کنندگان

با ابزار ConsumerGroupCommand می‌توانیم گروه‌های مصرف‌کننده را فهرست، توصیف یا حذف کنیم. یک گروه مصرف کننده را تنها زمانی می‌توان به صورت دستی حذف کرد که گروه هیچ عضو فعالی نداشته باشد. به عنوان مثال، برای فهرست کردن همه گروه های مصرف کننده در همه موضوعات:

```terminal
  > bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

    test-consumer-group
```

و برای مشاهده offsetها، گروه مصرف‌کننده را به شکل زیر توصیف می‌کنیم:

```terminal
  > bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group

  TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                    HOST            CLIENT-ID
  topic3          0          241019          395308          154289          consumer2-e76ea8c3-5d30-4299-9005-47eb41f3d3c4 /127.0.0.1      consumer2
  topic2          1          520678          803288          282610          consumer2-e76ea8c3-5d30-4299-9005-47eb41f3d3c4 /127.0.0.1      consumer2
  topic3          1          241018          398817          157799          consumer2-e76ea8c3-5d30-4299-9005-47eb41f3d3c4 /127.0.0.1      consumer2
  topic1          0          854144          855809          1665            consumer1-3fc8d6f1-581a-4472-bdf3-3515b4aee8c1 /127.0.0.1      consumer1
  topic2          0          460537          803290          342753          consumer1-3fc8d6f1-581a-4472-bdf3-3515b4aee8c1 /127.0.0.1      consumer1
  topic3          2          243655          398812          155157          consumer4-117fe4d3-c6c1-4178-8ee9-eb4a3954bee0 /127.0.0.1      consumer4
```


## امنیت 

### مروری بر امنیت 

از نسخه 0.9.0.0 کافکا، مواردی در جهت افزایش امنیت به آن اضافه شدند که برخی از آنها به شرح زیر هستند:
 

1. هویت سنجی برای اتصال client ها به بروکر. با استفاده از SSL یا SASL
2. رمزگذاری کانکتور هایی که بروکر ها را به zookeeper متصل می کنند.
3. رمزگداری داده هایی که بروکر ها منتقل می کنند.
4. اعطای مجوز برای خواندن/ نوشتن داده ها توسط client ها.
5. استفاده از مکانیزم خارجی برای هویت سنجی.

البته لازم به ذکر است که اجباری در جهت استفاده از این موارد ایمنی وجود ندارد
و مشکلی در اتصال بین خوشه هایی که این موارد را دارند و ندارند به وجود نخواهد آمد.

### تنظیمات listener 

برای این که یک خوشه از کافکا را ایمن کنیم، باید کانال های ارتباطی سرور ها را ایمن کنیم.
سرور ها listener هایی تعریف می کنند که از طریق آنها با سایر سرور ها و یا کلاینت ها در ارتباط باشند.
برای هر listener می توانیم شیوه هویت سنجی را مشخص کنیم تا امنیت سرور را تضمین کنیم.

سرور های کافکا می توانند بر روی پورت های مختلفی منتظر اتصال باشند.
تنظیم پورت ها از طریق تنظیمات سرور انجام پذیر است.
در این فایل می توان به فرمت زیر، چندین listener تعریف کرد که با یک ویرگول از هم جدا شده اند.

<div dir = "ltr">

```yaml
{LISTENER_NAME}://{hostname}:{port}
```

</div>

مثلا:

<div dir = "ltr">

```yaml
listeners=CLIENT://localhost:9092 
```

</div>

پروتکل امنیتی listener ها را می توان در فایل 
`listener.security.protocol.map`
که تنظیمات آن با کاما از هم جدا شده اند. مثلا در خط زیر،‌ تنظیمات برای دو listener انجام شده 
که اولی از پروتکل `SSL` و دومی  از پروتکل `PLAINTEXT` استفاده می کند:

<div dir = "ltr">

```yaml
listener.security.protocol.map=CLIENT:SSL,BROKER:PLAINTEXT
```

</div>

گزینه های قابل استفاده برای پروتکل امنیتی به شرح زیر هستند:

1. PLAINTEXT
2. SSL
3. SASL_PLAINTEXT
4. SASL_SSL

پروتکل `PLAINTEXT` هیچ گونه امکانات امنیتی ندارد و تنظیمات خاصی هم لازم ندارد.
 پس به سه مورد باقی مانده می پردازیم:




در یک خوشه KRaft، هر سروری که مقدار `broker` در `process.roles` برای مشخص شده باشد، `broker` خواهد بود
و هر سروری که مقدار `controller` برایش مشخص شده باشد، `controller` خواهد بود.
تنظیمات listener هم بسته به همین نقش متفاوت خواهد بود. listenerی که توسط `inter.broker.listener.name ` مشخص شده باشد
صرفا برای درخواست های بین broker ها استفاده می شود.
controller ها هم باید از listener های جداگانه استفاده کنند که در `controller.listener.names` تعریف شده اند.
این listener ها نمیتوانند با listenerهایی که برای ارتباط بین بروکر ها استفاده می شوند مشترک باشند.

controller ها هم از طرف سایر controller ها و هم از طرف broker ها درخواست دریافت می کنند.
در نتیجه حتی اگر سروری نقش controller نداشته باشد، باز هم باید listener های controller خود را به همراه تنظیمات امنیتی آنها مشخص کند.
به عنوان مثال، می توانیم از تنظیمات زیر برای یک broker مستقل استفاده کنیم:

<div dir = "ltr">

```yaml
process.roles=broker
listeners=BROKER://localhost:9092
inter.broker.listener.name=BROKER
controller.quorum.voters=0@localhost:9093
controller.listener.names=CONTROLLER
listener.security.protocol.map=BROKER:SASL_SSL,CONTROLLER:SASL_SSL
```

</div>

برای listener کنترلر در این تنظیمات مشخص شده که از از پروتکل `SASL_SSL` استفاده کند،
اما در لیست listener ها تعریف نشده است، چون broker قرار نیست که listener کنترلر را خودش باز کند.
پورتی که قرار است از آن استفاده شود، در `controller.quorum.voters` مشخص می شود که لیست کامل کنترلر ها را دارد.

برای سرور های KRaft که هم controller و هم broker هستند، این تنظیمات مشابه است.
با این تفاوت که listener باید در `listeners` مشخص شده باشد:

<div dir = "ltr">

```yaml
process.roles=broker,controller
listeners=BROKER://localhost:9092,CONTROLLER://localhost:9093
inter.broker.listener.name=BROKER
controller.quorum.voters=0@localhost:9093
controller.listener.names=CONTROLLER
listener.security.protocol.map=BROKER:SASL_SSL,CONTROLLER:SASL_SSL
```
</div>

پورتی که در `controller.quorum.voters` مشخص می شود باید دقیقا مطابق یکی از پورت های باز listener های کنترلر باشد.
که در مثال بالا هم این مورد رعایت شده است.

کنترلر درخواست هایی که برای هر یک از listener هایش هک در `controller.listener.names` تعریف شده باشد را قبول می کند.
کنترلر معمولا فقط یک listener دارد ولی می تواند چند تا هم داشته باشد.
با این کار مثلا می توان پورت یا پروتکل امنیتی listener را عوض کرد.
معمولا اولین پورتی که تعریف شده باشد، اولین آنها برای درخواست های به بیرون استفاده می شود.

### رمزگذاری و هویت سنجی با SSL

برای رمزگذاری ترافیک و هویت سنجی در کلاینت ها می توان از SSL استفاده کرد.
البته SSL به طور پیش فرض غیر فعال است و می توانید در صورت نیاز آن را روشن کنید.
در ادامه توضیح می دهیم که چطور زیرساخت PKI را خودتان راه اندازی کنید و با استفاده از آن
بتوانید certificate بسازید و kafka را برای استفاده از آن تنظیم کنید.

#### ساختن certificate و کلید SSL برای broker های کافکا 

برای راه اندازی یک یا چند بروکر کافکا که از SSL پشتیبانی کنند در ابتدا باید کلید های عمومی و خصوصی را برای هر سرور ایجاد کنیم.
از آنجا که کافکا انتظار دارد که تمام کلید ها و certificate ها در keystore ها ذخیره شده باشند، از دستور keytool جاوا برای آن استفاده می کنیم.
از آنچا که می خواهیم از فرمت PKCS12 استفاده کنیم،‌دستور را به صورت زیر می نویسیم:

<div dir = "ltr">

```commandline
keytool -keystore {keystorefile} -alias localhost -validity {validity} -genkey -keyalg RSA -storetype pkcs12
```
</div>

برای اجرای این دستور باید دو پارامتر را مشخص کنیم.

1. keystorefile: 
این فایل کلید های عمومی و خصوصی و certificate های هر بروکر را در خود نگه می دارد.
بنابراین باید در جایی امن نگه داشته شود.
در نتیجه بهتر است این فایل را فقط برای آن بروکری بفرستیم که کلید ها مربوط به آن است.

2.validity:
مدت زمانی که کلید ها معتبر هستند.

#### ساختن یک CA 

حال که یک سری کلید خصوصی و عمومی داریم، به یک مکانیزم مورد اعتماد برای امضای آنها نیاز داریم که در این مرحله آن را می سازیم.

CA مسیولیت امضای certificate ها را بر عهده دارد.
با استفاده از الگوریتم های رمزگذاری، جعل یک کلید بسیار سخت می شود و در نتیجه می توان از اصل بودن سروری که درخواست را برای ارسال می کنیم مطمین می شویم.

<div dir = "ltr">

```shell
HOME            = .
RANDFILE        = $ENV::HOME/.rnd

####################################################################
[ ca ]
default_ca    = CA_default      # The default ca section

[ CA_default ]

base_dir      = .
certificate   = $base_dir/cacert.pem   # The CA certifcate
private_key   = $base_dir/cakey.pem    # The CA private key
new_certs_dir = $base_dir              # Location for new certs after signing
database      = $base_dir/index.txt    # Database index file
serial        = $base_dir/serial.txt   # The current serial number

default_days     = 1000         # How long to certify for
default_crl_days = 30           # How long before next CRL
default_md       = sha256       # Use public key default MD
preserve         = no           # Keep passed DN ordering

x509_extensions = ca_extensions # The extensions to add to the cert

email_in_dn     = no            # Don't concat the email in the DN
copy_extensions = copy          # Required to copy SANs from CSR to cert

####################################################################
[ req ]
default_bits       = 4096
default_keyfile    = cakey.pem
distinguished_name = ca_distinguished_name
x509_extensions    = ca_extensions
string_mask        = utf8only

####################################################################
[ ca_distinguished_name ]
countryName         = Country Name (2 letter code)
countryName_default = DE

stateOrProvinceName         = State or Province Name (full name)
stateOrProvinceName_default = Test Province

localityName                = Locality Name (eg, city)
localityName_default        = Test Town

organizationName            = Organization Name (eg, company)
organizationName_default    = Test Company

organizationalUnitName         = Organizational Unit (eg, division)
organizationalUnitName_default = Test Unit

commonName         = Common Name (e.g. server FQDN or YOUR name)
commonName_default = Test Name

emailAddress         = Email Address
emailAddress_default = test@test.com

####################################################################
[ ca_extensions ]

subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid:always, issuer
basicConstraints       = critical, CA:true
keyUsage               = keyCertSign, cRLSign

####################################################################
[ signing_policy ]
countryName            = optional
stateOrProvinceName    = optional
localityName           = optional
organizationName       = optional
organizationalUnitName = optional
commonName             = supplied
emailAddress           = optional

####################################################################
[ signing_req ]
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid,issuer
basicConstraints       = CA:FALSE
keyUsage               = digitalSignature, keyEncipherment
```

</div>

سپس یک دیتابیس و فایل شماره سریال می سازیم که حساب certificate هایی که CA امضا کرده است را نگه داریم.
این فایل ها در کنار کلید های CA نگه داری می شوند:

<div dir = "ltr">

```text
> echo 01 > serial.txt
> touch index.txt
```

</div>

حال می توانیم CA را تولید کنیم:

<div dir = "ltr">

```bash
> openssl req -x509 -config openssl-ca.cnf -newkey rsa:4096 -sha256 -nodes -out cacert.pem -outform PEM
```

</div>

البته این فایل ها باید به طور کامل ایمن نگه داری شوند چون اگر کسی به آنها دسترسی داشته باشد می تواند هویت خود را جعل کند
و خودش را به جای سروری که مورد اعتماد شماست معرفی کند.

در گام بعد،‌این CA را به truststore کلاینت اضافه می کنیم که کلاینت ها به آن اعتماد داشته باشند.

<div dir = "ltr">

```bash
> keytool -keystore client.truststore.jks -alias CARoot -import -file ca-cert
```

</div>

#### امضای certificate 

برای امضای certificate با CA دستور زیر را می توان اجرا کرد:

<div dir = "ltr">

```bash
> openssl ca -config openssl-ca.cnf -policy signing_policy -extensions signing_req -out {server certificate} -infiles {certificate signing request}
```

</div>

در نهایت، باید Certificate خود CA و certificate امضا شده را به keystore اضافه کنیم:

<div dir = "ltr">

```bash
> keytool -keystore {keystore} -alias CARoot -import -file {CA certificate}
> keytool -keystore {keystore} -alias localhost -import -file cert-signed
```

</div>

#### تنظیم client های کافکا 

اگر که broker نیاز به هویت سنجی نداشته باشد، انجام این تنظیمات آسان است، 
چون برای producer و consumer یکسان است. یک مثال از فایل تنظیمات به صورت زیر است:

<div dir = "ltr">

```yaml
security.protocol=SSL
ssl.truststore.location=/var/private/ssl/client.truststore.jks
ssl.truststore.password=test1234
```

</div>

توجه داشته باشید که 
`ssl.truststore.password`
اختیاری است اما داشتن آن اکیدا توصیه می شود. چون بدون آن، امکان دسترسی به truststore وجود دارد
و اصالت سنجی هم غیر فعال است. اگر اعتبارسنجی client فعال باشد، باید یک keystore را هم تعریف کنیم.

<div dir = "ltr"> 

```yaml
ssl.keystore.location=/var/private/ssl/client.keystore.jks
ssl.keystore.password=test1234
ssl.key.password=test1234
```

</div>

#### تنظیم broker های کافکا 

اگر ssl برای ارتباط بین بروکر ها فعال نشده باشد، باید هم برای PLAINTEXT و هم برای SSL پورت تنظیم شود.

<div dir = "ltr"> 

```yaml
listeners=PLAINTEXT://host.name:port,SSL://host.name:port
```

</div>

<div dir = "ltr"> 

```yaml
ssl.keystore.location=/var/private/ssl/server.keystore.jks
ssl.keystore.password=test1234
ssl.key.password=test1234
ssl.truststore.location=/var/private/ssl/server.truststore.jks
ssl.truststore.password=test1234
```

</div>


## KAFKA CONNECT

### پیش درآمد 

KAFKA CONNECT 
ابزاری است که با استفاده از آن می توان به صورت مقیاس پذیر و مطمین، داده ها را بین کافکا و سایر سیستم ها منتقل کرد.
با استفاده از آن می توان به راحتی connector هایی تعریف کرد که مجموعه های بزرگی از داده را به داخل و خارج کافکا منتقل می کنند.
Kafka Connect 
میتواند پایگاه داده ها و یا گزارشات برنامه ها را هم به تاپیک های کافکا منتقل کند که با این کار،
داده ها برای پردازش در یک جریان داده با تاخیر پایین مهیا می شوند.
همچنین با کمک job های export، میتوان داده ی کافکا را به سیستم ها یا پایگاه داده های دیگر منتقل کرد و یا آنها را برای پردازش آفلاین استفاده کرد.

از امکانات Kafka Connect می توان به موارد زیر اشاره کرد:

- یک چهارچوب مشترک برای کانکتور های کافکا:
از آنجا که در Kafka Connect استاندارد های اتصال به کافکا تعریف می شود، در نتیجه توسعه و اجرای کانکتور ها راحت تر صورت می پذیرد.

- گره های توزیع شده و مستقل:
امکان مقیاس پذیری در آن هم به سمت بالا و هم سمت پایین وجود دارد.

- رابط REST:
با استفاده از رابط Rest API،‌امکان مدیریت کانکتور های کافکا به راحتی وجود دارد.

- مدیریت خودکار آفست ها:
در صورتی که Kafka Connect اطلاعاتی اندک در مورد connector ها داشته باشد، می تواند کار commit کردن آفست ها را انجام دهد
و این بخش که ممکن است باعث ایجاد باگ شود را از روی دوش برنامه نویس بردارد.

- توزیع پذیر و مقیاس پذیر:
Kafka Connect
پروتکل group management را توسعه می دهد. در نتیجه به راحتی می توان در هر زمان تعداد worker ها را تغییر داد.

- توانایی اتصال سرویس های streaming و batch:
با توجه به قابلیت های کافکا، امکان اتصال سیستم های streaming و batch وجود دارد.


</div>




